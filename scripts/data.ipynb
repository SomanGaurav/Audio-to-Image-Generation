{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e7f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "captions = np.load(\"nov_data/captions.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d58e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Captions Shape :- {captions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf82f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(captions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ab4396",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'runtime (Python 3.10.9)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/ie643_therelutionaries/runcode/runtime/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusion3Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deae607",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusion3Pipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-3-medium-diffusers\", # Using the diffusers-specific ID\n",
    "    torch_dtype=torch.float16,\n",
    "   \n",
    ").to(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf2bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classname = \"women laughs bird \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bc04d7",
   "metadata": {},
   "source": [
    "made changes in the sd3 pipeline to return the individual output of the encodings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91448c02",
   "metadata": {},
   "source": [
    "### Extracting pooled embeddings for captions.npy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a5988",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeebd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# captions_pooled_embeddings = []\n",
    "# for idx , caption in enumerate(captions):\n",
    "#     with torch.no_grad(): \n",
    "#         (\n",
    "#         prompt_embeds,\n",
    "#         negative_prompt_embeds,\n",
    "#         pooled_prompt_embeds,\n",
    "#         negative_pooled_prompt_embeds,\n",
    "#         embed1 , \n",
    "#         embed2 , \n",
    "#         embed3 , \n",
    "#     ) = pipe.encode_prompt(\n",
    "#         prompt=classname,\n",
    "#         prompt_2=classname,\n",
    "#         prompt_3=classname,\n",
    "#         device=pipe.device, # Good practice to specify device\n",
    "#         num_images_per_prompt=1,\n",
    "#         do_classifier_free_guidance=True\n",
    "#     )\n",
    "    \n",
    "#     captions_pooled_embeddings.append(pooled_prompt_embeds.tolist())\n",
    "#     print(f\"\\rEmbeddings created upto index :- {idx}\",end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6949bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_pooled_embeddings = []\n",
    "\n",
    "for idx, caption in enumerate(captions):\n",
    "    with torch.no_grad():\n",
    "        (\n",
    "            prompt_embeds,\n",
    "            negative_prompt_embeds,\n",
    "            pooled_prompt_embeds,\n",
    "            negative_pooled_prompt_embeds,\n",
    "            embed1 , \n",
    "            embed2 , \n",
    "            embed3 , \n",
    "        ) = pipe.encode_prompt(\n",
    "            prompt=caption,\n",
    "            prompt_2 = caption,\n",
    "            prompt_3=caption,\n",
    "            device=pipe.device,\n",
    "            num_images_per_prompt=1,\n",
    "            do_classifier_free_guidance=True\n",
    "        )\n",
    "\n",
    "    captions_pooled_embeddings.append(pooled_prompt_embeds.cpu().tolist())\n",
    "    print(f\"\\rEmbeddings created up to index: {idx}\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ac872",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(captions_pooled_embeddings)\n",
    "np.save(\"pooled_embeds.npy\" , arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc09290",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_embed_captions = np.load(\"pooled_embeds.npy\")\n",
    "print(pooled_embed_captions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45ceb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "del captions_pooled_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ae6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataemb = np.load(\"pooled_embeds.npy\")\n",
    "print(dataemb[0])\n",
    "print(dataemb[1])\n",
    "print(dataemb[2])\n",
    "print(dataemb[3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fffdc02",
   "metadata": {},
   "source": [
    "### Extracting prompt embeddings for token_captions.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc40b3b7",
   "metadata": {},
   "source": [
    "### Section Over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788bc762",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = np.load(\"nov_data/token_captions.npy\")\n",
    "print(captions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67bbdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings_1 = []\n",
    "token_embeddings_2 = []\n",
    "token_embeddings_3 = []\n",
    "\n",
    "for idx, caption in enumerate(captions):\n",
    "    with torch.no_grad():\n",
    "        (_, _, _, _, embed1, embed2, embed3) = pipe.encode_prompt(\n",
    "            prompt=caption,\n",
    "            prompt_2=caption,\n",
    "            prompt_3=caption,\n",
    "            device=pipe.device,\n",
    "            num_images_per_prompt=1,\n",
    "            do_classifier_free_guidance=True\n",
    "        )\n",
    "\n",
    "    embed1 = embed1.detach().cpu().numpy()[:, :20, :]\n",
    "    embed2 = embed2.detach().cpu().numpy()[:, :20, :]\n",
    "    embed3 = embed3.detach().cpu().numpy()[:, :20, :]\n",
    "\n",
    "    token_embeddings_1.append(embed1)\n",
    "    token_embeddings_2.append(embed2)\n",
    "    token_embeddings_3.append(embed3)\n",
    "\n",
    "    print(f\"\\rEmbeddings created upto index :- {idx}\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2080ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings_1 = np.concatenate(token_embeddings_1, axis=0)\n",
    "token_embeddings_2 = np.concatenate(token_embeddings_2, axis=0)\n",
    "token_embeddings_3 = np.concatenate(token_embeddings_3, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2484b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd3f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"clipl_embeds.npy\", token_embeddings_1)\n",
    "np.save(\"clipg_embeds.npy\", token_embeddings_2)\n",
    "np.save(\"t5_embeds.npy\", token_embeddings_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54178c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings_1 = np.load(\"clipl_embeds.npy\")\n",
    "token_embeddings_2 = np.load(\"clipg_embeds.npy\")\n",
    "token_embeddings_3 = np.load(\"t5_embeds.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a734d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "token_embeddings_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        # Unpack the four output tensors\n",
    "        (\n",
    "        prompt_embeds,\n",
    "        negative_prompt_embeds,\n",
    "        pooled_prompt_embeds,\n",
    "        negative_pooled_prompt_embeds,\n",
    "        embed1 , \n",
    "        embed2 , \n",
    "        embed3 , \n",
    "    ) = pipe.encode_prompt(\n",
    "        prompt=classname,\n",
    "        prompt_2=classname,\n",
    "        prompt_3=classname,\n",
    "        device=pipe.device, # Good practice to specify device\n",
    "        num_images_per_prompt=1,\n",
    "        do_classifier_free_guidance=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19c5a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of pooled_embeddings :- {pooled_prompt_embeds.shape}\")\n",
    "print(f\"Shape of prompt embeddings :- {prompt_embeds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b1baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of embed 1 :- {embed1.shape}\")\n",
    "print(f\"Shape of embed 2 :- {embed2.shape}\")\n",
    "print(f\"Shape of embed 3 :- {embed3.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2cdace",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = pipe.tokenizer(\n",
    "    classname,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "tokens['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba76a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_tokens = pipe.tokenizer_2(\n",
    "    classname,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "t5_tokens['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0ca72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_tokens = pipe.tokenizer_3(\n",
    "    classname,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "t5_tokens['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3950ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_decoded = pipe.tokenizer_3.convert_ids_to_tokens(t5_tokens.input_ids[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf416f2",
   "metadata": {},
   "source": [
    "Dont run the below cell . use the pipe pipefunction/images[] to explor the sd3 library to understand the working of the code . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c4a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = pipe(\n",
    "#     prompt=None,\n",
    "#     negative_prompt=None,\n",
    "#     pooled_prompt_embeds=torch.tensor(pooled_pred, dtype=torch.float16).to(\"cuda:1\"),\n",
    "#     prompt_embeds=torch.tensor(prompt_embeds, dtype=torch.float16).to(\"cuda:1\"),\n",
    "#     num_inference_steps=28,\n",
    "#     guidance_scale=7.0\n",
    "# ).images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af969dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed1[0][18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fac9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = embed1[0][1:] - embed1[0][:-1]\n",
    "distances = torch.norm(diff, dim=1)\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd1962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "runtime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
